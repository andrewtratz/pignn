{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/ArmanMaesumi/torchrbf/\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "'''\n",
    "Radial basis functions:\n",
    "'''\n",
    "eps = 1e-7\n",
    "\n",
    "def linear(r):\n",
    "    return -r\n",
    "\n",
    "def thin_plate_spline(r):\n",
    "    r = torch.clamp(r, min=eps)\n",
    "    return r**2 * torch.log(r)\n",
    "\n",
    "def cubic(r):\n",
    "    return r**3\n",
    "\n",
    "def quintic(r):\n",
    "    return -r**5\n",
    "\n",
    "def multiquadric(r):\n",
    "    return -torch.sqrt(r**2 + 1)\n",
    "\n",
    "def inverse_multiquadric(r):\n",
    "    return 1/torch.sqrt(r**2 + 1)\n",
    "\n",
    "def inverse_quadratic(r):\n",
    "    return 1/(r**2 + 1)\n",
    "\n",
    "def gaussian(r):\n",
    "    return torch.exp(-r**2)\n",
    "\n",
    "RADIAL_FUNCS = {\n",
    "   \"linear\": linear,\n",
    "   \"thin_plate_spline\": thin_plate_spline,\n",
    "   \"cubic\": cubic,\n",
    "   \"quintic\": quintic,\n",
    "   \"multiquadric\": multiquadric,\n",
    "   \"inverse_multiquadric\": inverse_multiquadric,\n",
    "   \"inverse_quadratic\": inverse_quadratic,\n",
    "   \"gaussian\": gaussian\n",
    "   }\n",
    "\n",
    "SCALE_INVARIANT = {\"linear\", \"thin_plate_spline\", \"cubic\", \"quintic\"}\n",
    "\n",
    "MIN_DEGREE = {\n",
    "    \"multiquadric\": 0,\n",
    "    \"linear\": 0,\n",
    "    \"thin_plate_spline\": 1,\n",
    "    \"cubic\": 1,\n",
    "    \"quintic\": 2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/ArmanMaesumi/torchrbf/\n",
    "\n",
    "import numpy as np\n",
    "import contextlib\n",
    "import warnings\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from itertools import combinations_with_replacement\n",
    "# from .radial_fn import SCALE_INVARIANT, RADIAL_FUNCS, MIN_DEGREE\n",
    "\n",
    "\n",
    "# SEED = 12345\n",
    "# np.random.seed(SEED)\n",
    "# torch.manual_seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.set_num_threads(1)\n",
    "\n",
    "\n",
    "class RBFInterpolator(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Radial basis function interpolator in Pytorch. This is a port of\n",
    "    the RBFInterpolator from scipy.interpolate.RBFInterpolator. With\n",
    "    GPU acceleration, this is much faster than the scipy version.\n",
    "    SciPy reference: https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.RBFInterpolator.html\n",
    "\n",
    "    @param y: (n, d) tensor of data point coordinates\n",
    "    @param d: (n, m) tensor of data vectors at y\n",
    "    @param neighbors (optional): int [CURRENTLY UNIMPLEMENTED] specifies the\n",
    "        number of neighbors to use for each interpolation point. If\n",
    "        None, all points are used.\n",
    "        Default is None.\n",
    "    @param smoothing (optional): float or (n,) tensor of smoothing parameters\n",
    "        Default is 0.0.\n",
    "    @param kernel (optional): str, kernel function to use; one of\n",
    "        ['linear', 'thin_plate_spline', 'cubic', 'quintic', 'gaussian'\n",
    "        'multiquadric', 'inverse_multiquadric', 'inverse_quadratic']\n",
    "        Default is 'thin_plate_spline'.\n",
    "    @param epsilon (optional): float, shape parameter for the kernel function.\n",
    "        If kernel is 'linear', 'thin_plate_spline', 'cubic', or\n",
    "        'quintic', then default is 1.0 and can be ignored. Must be\n",
    "        specified otherwise.\n",
    "    @param degree (optional): int, degree of the polynomial added to the\n",
    "        interpolation function. See scipy.interpolate.RBFInterpolator\n",
    "        for more details.\n",
    "    @param device (optional): str, specifies the default device to store tensors\n",
    "        and perform interpolation.\n",
    "\n",
    "    Returns a callable Torch Module that interpolates the data at given points.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        y,\n",
    "        d,\n",
    "        neighbors=None,\n",
    "        smoothing=0.0,\n",
    "        kernel=\"thin_plate_spline\",\n",
    "        epsilon=None,\n",
    "        degree=None,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if torch.backends.cuda.matmul.allow_tf32:\n",
    "            warnings.warn(\n",
    "                \"TF32 is enabled, which may cause numerical issues in PyTorch RBFInterpolator. \"\n",
    "                \"Consider disabling it with torch.backends.cuda.matmul.allow_tf32 = False\",\n",
    "                UserWarning,\n",
    "            )\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        # init:\n",
    "        if isinstance(y, np.ndarray):\n",
    "            y = torch.from_numpy(y).to(device=device).float()\n",
    "\n",
    "        if y.ndim != 2:\n",
    "            raise ValueError(\"y must be a 2-dimensional tensor.\")\n",
    "\n",
    "        ny, ndim = y.shape\n",
    "        if isinstance(d, np.ndarray):\n",
    "            d = torch.from_numpy(d).to(device=device).float()\n",
    "\n",
    "        if d.shape[0] != ny:\n",
    "            raise ValueError(\n",
    "                \"The first dim of d must have the same length as the first dim of y.\"\n",
    "            )\n",
    "\n",
    "        d_shape = d.shape[1:]\n",
    "        d = d.reshape((ny, -1))\n",
    "\n",
    "        if isinstance(smoothing, (int, float)):\n",
    "            smoothing = torch.full((ny,), smoothing, device=device).float()\n",
    "        elif isinstance(smoothing, np.ndarray):\n",
    "            smoothing = torch.Tensor(smoothing).to(device=device).float()\n",
    "        elif not isinstance(smoothing, torch.Tensor):\n",
    "            raise ValueError(\"`smoothing` must be a scalar or a 1-dimensional tensor.\")\n",
    "\n",
    "        kernel = kernel.lower()\n",
    "        if kernel not in RADIAL_FUNCS:\n",
    "            raise ValueError(f\"Unknown kernel: {kernel}\")\n",
    "\n",
    "        if epsilon is None:\n",
    "            if kernel in SCALE_INVARIANT:\n",
    "                epsilon = 1.0\n",
    "            else:\n",
    "                raise ValueError(\"Must specify `epsilon` for this kernel.\")\n",
    "        else:\n",
    "            epsilon = float(epsilon)\n",
    "\n",
    "        min_degree = MIN_DEGREE.get(kernel, -1)\n",
    "        if degree is None:\n",
    "            degree = max(min_degree, 0)\n",
    "        else:\n",
    "            degree = int(degree)\n",
    "            if degree < -1:\n",
    "                raise ValueError(\"`degree` must be at least -1.\")\n",
    "            elif degree < min_degree:\n",
    "                warnings.warn(\n",
    "                    f\"`degree` is too small for this kernel. Setting to {min_degree}.\",\n",
    "                    UserWarning,\n",
    "                )\n",
    "\n",
    "        if neighbors is None:\n",
    "            nobs = ny\n",
    "        else:\n",
    "            raise ValueError(\"neighbors currently not supported\")\n",
    "\n",
    "        powers = monomial_powers(ndim, degree).to(device=device)\n",
    "        if powers.shape[0] > nobs:\n",
    "            raise ValueError(\"The data is not compatible with the requested degree.\")\n",
    "\n",
    "        if neighbors is None:\n",
    "            shift, scale, coeffs = solve(y, d, smoothing, kernel, epsilon, powers)\n",
    "            self.register_buffer(\"_shift\", shift)\n",
    "            self.register_buffer(\"_scale\", scale)\n",
    "            self.register_buffer(\"_coeffs\", coeffs)\n",
    "\n",
    "        self.register_buffer(\"y\", y)\n",
    "        self.register_buffer(\"d\", d)\n",
    "        self.register_buffer(\"smoothing\", smoothing)\n",
    "        self.register_buffer(\"powers\", powers)\n",
    "\n",
    "        self.d_shape = d_shape\n",
    "        self.neighbors = neighbors\n",
    "        self.kernel = kernel\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Returns the interpolated data at the given points `x`.\n",
    "\n",
    "        @param x: (n, d) tensor of points at which to query the interpolator\n",
    "        @param use_grad (optional): bool, whether to use Torch autograd when\n",
    "            querying the interpolator. Default is False.\n",
    "\n",
    "        Returns a (n, m) tensor of interpolated data.\n",
    "        \"\"\"\n",
    "        if x.ndim != 2:\n",
    "            raise ValueError(\"`x` must be a 2-dimensional tensor.\")\n",
    "\n",
    "        nx, ndim = x.shape\n",
    "        if ndim != self.y.shape[1]:\n",
    "            raise ValueError(\n",
    "                \"Expected the second dim of `x` to have length \"\n",
    "                f\"{self.y.shape[1]}.\"\n",
    "            )\n",
    "\n",
    "        kernel_func = RADIAL_FUNCS[self.kernel]\n",
    "\n",
    "        yeps = self.y * self.epsilon\n",
    "        xeps = x * self.epsilon\n",
    "        xhat = (x - self._shift) / self._scale\n",
    "\n",
    "        kv = kernel_vector(xeps, yeps, kernel_func)\n",
    "        p = polynomial_matrix(xhat, self.powers)\n",
    "        vec = torch.cat([kv, p], dim=1)\n",
    "        out = torch.matmul(vec, self._coeffs)\n",
    "        out = out.reshape((nx,) + self.d_shape)\n",
    "        return out\n",
    "\n",
    "\n",
    "def kernel_vector(x, y, kernel_func):\n",
    "    \"\"\"Evaluate radial functions with centers `y` for all points in `x`.\"\"\"\n",
    "    return kernel_func(torch.cdist(x, y, compute_mode=\"use_mm_for_euclid_dist\"))\n",
    "\n",
    "\n",
    "def polynomial_matrix(x, powers):\n",
    "    \"\"\"Evaluate monomials at `x` with given `powers`\"\"\"\n",
    "    x_ = torch.repeat_interleave(x, repeats=powers.shape[0], dim=0)\n",
    "    powers_ = powers.repeat(x.shape[0], 1)\n",
    "    return torch.prod(x_**powers_, dim=1).view(x.shape[0], powers.shape[0])\n",
    "\n",
    "\n",
    "def kernel_matrix(x, kernel_func):\n",
    "    \"\"\"Returns radial function values for all pairs of points in `x`.\"\"\"\n",
    "    return kernel_func(torch.cdist(x, x, compute_mode=\"use_mm_for_euclid_dist\"))\n",
    "\n",
    "\n",
    "def monomial_powers(ndim, degree):\n",
    "    \"\"\"Return the powers for each monomial in a polynomial.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ndim : int\n",
    "        Number of variables in the polynomial.\n",
    "    degree : int\n",
    "        Degree of the polynomial.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (nmonos, ndim) int ndarray\n",
    "        Array where each row contains the powers for each variable in a\n",
    "        monomial.\n",
    "\n",
    "    \"\"\"\n",
    "    nmonos = math.comb(degree + ndim, ndim)\n",
    "    out = torch.zeros((nmonos, ndim), dtype=torch.int32)\n",
    "    count = 0\n",
    "    for deg in range(degree + 1):\n",
    "        for mono in combinations_with_replacement(range(ndim), deg):\n",
    "            for var in mono:\n",
    "                out[count, var] += 1\n",
    "            count += 1\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def build(y, d, smoothing, kernel, epsilon, powers):\n",
    "    \"\"\"Build the RBF linear system\"\"\"\n",
    "\n",
    "    p = d.shape[0]\n",
    "    s = d.shape[1]\n",
    "    r = powers.shape[0]\n",
    "    kernel_func = RADIAL_FUNCS[kernel]\n",
    "\n",
    "    mins = torch.min(y, dim=0).values\n",
    "    maxs = torch.max(y, dim=0).values\n",
    "    shift = (maxs + mins) / 2\n",
    "    scale = (maxs - mins) / 2\n",
    "\n",
    "    scale[scale == 0.0] = 1.0\n",
    "\n",
    "    yeps = y * epsilon\n",
    "    yhat = (y - shift) / scale\n",
    "\n",
    "    lhs = torch.empty((p + r, p + r), device=d.device).float()\n",
    "    lhs[:p, :p] = kernel_matrix(yeps, kernel_func)\n",
    "    lhs[:p, p:] = polynomial_matrix(yhat, powers)\n",
    "    lhs[p:, :p] = lhs[:p, p:].T\n",
    "    lhs[p:, p:] = 0.0\n",
    "    lhs[:p, :p] += torch.diag(smoothing)\n",
    "\n",
    "    rhs = torch.empty((r + p, s), device=d.device).float()\n",
    "    rhs[:p] = d\n",
    "    rhs[p:] = 0.0\n",
    "\n",
    "    return lhs, rhs, shift, scale\n",
    "\n",
    "\n",
    "def solve(y, d, smoothing, kernel, epsilon, powers):\n",
    "    \"\"\"Build then solve the RBF linear system\"\"\"\n",
    "\n",
    "    lhs, rhs, shift, scale = build(y, d, smoothing, kernel, epsilon, powers)\n",
    "    try:\n",
    "        coeffs = torch.linalg.solve(lhs, rhs)\n",
    "    except RuntimeError:  # singular matrix\n",
    "        if coeffs is None:\n",
    "            msg = \"Singular matrix.\"\n",
    "            nmonos = powers.shape[0]\n",
    "            if nmonos > 0:\n",
    "                pmat = polynomial_matrix((y - shift) / scale, powers)\n",
    "                rank = torch.linalg.matrix_rank(pmat)\n",
    "                if rank < nmonos:\n",
    "                    msg = (\n",
    "                        \"Singular matrix. The matrix of monomials evaluated at \"\n",
    "                        \"the data point coordinates does not have full column \"\n",
    "                        f\"rank ({rank}/{nmonos}).\"\n",
    "                    )\n",
    "\n",
    "            raise ValueError(msg)\n",
    "\n",
    "    return shift, scale, coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# y = torch.rand(100, 2) # Data coordinates\n",
    "# d = torch.rand(100, 3) # Data vectors at each point\n",
    "\n",
    "# interpolator = RBFInterpolator(y, d, smoothing=1.0, kernel='thin_plate_spline')\n",
    "\n",
    "# # Query coordinates (100x100 grid of points)\n",
    "# x = torch.linspace(0, 1, 100)\n",
    "# y = torch.linspace(0, 1, 100)\n",
    "# grid_points = torch.meshgrid(x, y, indexing='ij')\n",
    "# grid_points = torch.stack(grid_points, dim=-1).reshape(-1, 2)\n",
    "\n",
    "# # Query RBF on grid points\n",
    "# interp_vals = interpolator(grid_points)\n",
    "\n",
    "# # Plot the interpolated values in 2D\n",
    "# plt.scatter(grid_points[:, 0], grid_points[:, 1], c=interp_vals[:, 0])\n",
    "# plt.title('Interpolated values in 2D')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips import get_root_path\n",
    "from lips.dataset import airfransDataSet\n",
    "from lips.dataset.airfransDataSet import AirfRANSDataSet\n",
    "from lips.benchmark.airfransBenchmark import AirfRANSBenchmark\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from airfrans.simulation import Simulation\n",
    "import pyvista as pv\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate required paths\n",
    "LIPS_PATH = get_root_path()\n",
    "DIRECTORY_NAME = '../../Airfrans/Dataset'\n",
    "BENCHMARK_NAME = \"Case1\"\n",
    "LOG_PATH = LIPS_PATH + \"lips_logs.log\"\n",
    "BENCH_CONFIG_PATH = os.path.join(\"../../Kit\", \"airfoilConfigurations\",\"benchmarks\",\"confAirfoil.ini\") #Configuration file related to the benchmark\n",
    "SIM_CONFIG_PATH = os.path.join(\"../../Kit\", \"airfoilConfigurations\",\"simulators\",\"torch_fc.ini\") #Configuration file re\n",
    "# print(BENCH_CONFIG_PATH)\n",
    "\n",
    "# Scalers\n",
    "PRESS_SCALE = 1600.0\n",
    "TURB_SCALE = 0.01\n",
    "SPEED_SCALE = 75.0\n",
    "DEFAULT_SCALE = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset (task: scarce, split: train): 100%|██████████| 200/200 [00:28<00:00,  7.04it/s]\n",
      "Loading dataset (task: full, split: test):  32%|███▏      | 64/200 [00:09<00:19,  6.98it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m benchmark\u001b[38;5;241m=\u001b[39mAirfRANSBenchmark(benchmark_path \u001b[38;5;241m=\u001b[39m DIRECTORY_NAME,\n\u001b[1;32m      2\u001b[0m                             config_path \u001b[38;5;241m=\u001b[39m BENCH_CONFIG_PATH,\n\u001b[1;32m      3\u001b[0m                             benchmark_name \u001b[38;5;241m=\u001b[39m BENCHMARK_NAME,\n\u001b[1;32m      4\u001b[0m                             log_path \u001b[38;5;241m=\u001b[39m LOG_PATH)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDIRECTORY_NAME\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CFD/venv_cfd/lib/python3.11/site-packages/lips/benchmark/airfransBenchmark.py:130\u001b[0m, in \u001b[0;36mAirfRANSBenchmark.load\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    125\u001b[0m simulation_indices_train\u001b[38;5;241m=\u001b[39mreynolds_filter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset\u001b[38;5;241m=\u001b[39mextract_dataset_by_simulations(newdataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    127\u001b[0m                                                   dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset,\n\u001b[1;32m    128\u001b[0m                                                   simulation_indices\u001b[38;5;241m=\u001b[39msimulation_indices_train)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_ood_dataset\u001b[38;5;241m.\u001b[39mload(path \u001b[38;5;241m=\u001b[39m path)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CFD/venv_cfd/lib/python3.11/site-packages/lips/dataset/airfransDataSet.py:61\u001b[0m, in \u001b[0;36mAirfRANSDataSet.load\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     59\u001b[0m indices_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(variables,\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(variables))))\n\u001b[1;32m     60\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m dataset, simulation_names \u001b[38;5;241m=\u001b[39m \u001b[43maf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m simulation_size \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataset])[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     63\u001b[0m simulation_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([np\u001b[38;5;241m.\u001b[39marray(simulation_names)[:, \u001b[38;5;28;01mNone\u001b[39;00m], simulation_size], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/CFD/venv_cfd/lib/python3.11/site-packages/airfrans/dataset.py:104\u001b[0m, in \u001b[0;36mload\u001b[0;34m(root, task, train)\u001b[0m\n\u001b[1;32m    102\u001b[0m name_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m tqdm(manifest, desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading dataset (task: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtaskk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, split: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 104\u001b[0m     simulation \u001b[38;5;241m=\u001b[39m \u001b[43mSimulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     inlet_velocity \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mcos(simulation\u001b[38;5;241m.\u001b[39mangle_of_attack),\\\n\u001b[1;32m    106\u001b[0m             np\u001b[38;5;241m.\u001b[39msin(simulation\u001b[38;5;241m.\u001b[39mangle_of_attack)])\u001b[38;5;241m*\u001b[39msimulation\u001b[38;5;241m.\u001b[39minlet_velocity)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\\\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones_like(simulation\u001b[38;5;241m.\u001b[39msdf)\n\u001b[1;32m    109\u001b[0m     attribute \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\n\u001b[1;32m    110\u001b[0m         simulation\u001b[38;5;241m.\u001b[39mposition,\n\u001b[1;32m    111\u001b[0m         inlet_velocity,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m         simulation\u001b[38;5;241m.\u001b[39msurface\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    118\u001b[0m     ], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/CFD/venv_cfd/lib/python3.11/site-packages/airfrans/simulation.py:31\u001b[0m, in \u001b[0;36mSimulation.__init__\u001b[0;34m(self, root, name, T)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(T) \u001b[38;5;66;03m# Temperature in Kelvin\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CFD/venv_cfd/lib/python3.11/site-packages/airfrans/simulation.py:43\u001b[0m, in \u001b[0;36mSimulation.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minlet_velocity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m2\u001b[39m]))\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mangle_of_attack \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m3\u001b[39m])\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m180\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal \u001b[38;5;241m=\u001b[39m \u001b[43mpv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mosp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_internal.vtu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mairfoil \u001b[38;5;241m=\u001b[39m pv\u001b[38;5;241m.\u001b[39mread(osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_aerofoil.vtp\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal\u001b[38;5;241m.\u001b[39mcompute_cell_sizes(length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, volume \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/CFD/venv_cfd/lib/python3.11/site-packages/pyvista/core/utilities/fileio.py:202\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, force_ext, file_format, progress_bar)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_bar:\n\u001b[1;32m    201\u001b[0m     reader\u001b[38;5;241m.\u001b[39mshow_progress()\n\u001b[0;32m--> 202\u001b[0m mesh \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observer\u001b[38;5;241m.\u001b[39mhas_event_occurred():\n\u001b[1;32m    204\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe VTK reader `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreader\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mGetClassName()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in pyvista reader `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreader\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` raised an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile reading the file.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobserver\u001b[38;5;241m.\u001b[39mget_message()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    208\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/CFD/venv_cfd/lib/python3.11/site-packages/pyvista/core/utilities/reader.py:408\u001b[0m, in \u001b[0;36mBaseReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read data in file.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03mReturns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m    PyVista Dataset.\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyvista\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _update_alg  \u001b[38;5;66;03m# avoid circular import\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m \u001b[43m_update_alg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_progress_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_progress_msg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m data \u001b[38;5;241m=\u001b[39m wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mGetOutputDataObject(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CFD/venv_cfd/lib/python3.11/site-packages/pyvista/core/filters/__init__.py:40\u001b[0m, in \u001b[0;36m_update_alg\u001b[0;34m(alg, progress_bar, message)\u001b[0m\n\u001b[1;32m     38\u001b[0m         alg\u001b[38;5;241m.\u001b[39mUpdate()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[43malg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUpdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "benchmark=AirfRANSBenchmark(benchmark_path = DIRECTORY_NAME,\n",
    "                            config_path = BENCH_CONFIG_PATH,\n",
    "                            benchmark_name = BENCHMARK_NAME,\n",
    "                            log_path = LOG_PATH)\n",
    "benchmark.load(path=DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pressure': -395.22959540860137, 'turbulent_viscosity': 0.0008392954292084482, 'speed': 63.15423170302567, 'position': 0.0}\n",
      "{'pressure': 2425.738434726353, 'turbulent_viscosity': 0.0030420989011928183, 'speed': 8.487422521188462, 'position': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Create normalizing constants\n",
    "MEANS = {}\n",
    "STDS = {}\n",
    "\n",
    "for var in ['x-position', 'y-position', 'x-inlet_velocity', 'x-velocity', 'pressure', 'turbulent_viscosity']:\n",
    "    MEANS[var] = np.mean(benchmark.train_dataset.data[var])\n",
    "    STDS[var] = np.std(benchmark.train_dataset.data[var])\n",
    "\n",
    "MEANS['speed'] = MEANS['x-inlet_velocity']\n",
    "STDS['speed'] = STDS['x-inlet_velocity']\n",
    "MEANS['position'] = 0.0\n",
    "STDS['position'] = 1.0\n",
    "\n",
    "for var in ['x-position', 'y-position', 'x-inlet_velocity', 'x-velocity']:\n",
    "    MEANS.pop(var, None)\n",
    "    STDS.pop(var, None)\n",
    "\n",
    "print(MEANS)\n",
    "print(STDS)\n",
    "\n",
    "x_means = np.zeros(2, dtype=np.float32)\n",
    "x_stds = np.zeros(2, dtype=np.float32)\n",
    "y_means = np.zeros(4, dtype=np.float32)\n",
    "y_stds = np.zeros(4, dtype=np.float32)\n",
    "\n",
    "for i, var in zip(range(2), ['position', 'speed']):        \n",
    "    x_means[i] = MEANS[var]\n",
    "    x_stds[i] = STDS[var]\n",
    "\n",
    "for i, var in zip(range(4), ['position', 'speed', 'pressure', 'turbulent_viscosity']):        \n",
    "    y_means[i] = MEANS[var]\n",
    "    y_stds[i] = STDS[var]\n",
    "\n",
    "MEANS['pressure'] = 0.0\n",
    "MEANS['turbulent_viscosity'] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge functions\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Create label and data array for single edge\n",
    "def make_edge(a, b):\n",
    "    label = str(a) + '_' + str(b)\n",
    "    return label, np.array([a,b], dtype=int)\n",
    "\n",
    "\n",
    "# Line from a to b\n",
    "def delta_vector(from_v, to_v):\n",
    "    return to_v-from_v\n",
    "\n",
    "def angle_off_x_axis(a):\n",
    "    # Note that both vectors begin at the origin, so we actually want them compared vs. [1,0]\n",
    "    # if len(a.shape) < 2:\n",
    "    #     a = np.expand_dims(a, 1)\n",
    "    if len(a.shape) < 2:\n",
    "        norm = np.linalg.norm(a)\n",
    "        out = np.ones_like(norm)\n",
    "        out = np.arccos(np.divide(a.dot(np.array([1,0])),norm))\n",
    "\n",
    "    else:\n",
    "        norm = np.linalg.norm(a, axis=1)\n",
    "        out = np.ones_like(norm)\n",
    "        out[np.where(norm > 0)] = np.arccos(np.divide(np.squeeze(a[np.where(norm > 0)]).dot(np.array([1,0])),np.squeeze(norm[np.where(norm > 0)])))\n",
    "    return out\n",
    "\n",
    "# Create all edges\n",
    "def make_edges(sim):\n",
    "    cells = sim.internal.cells_dict[9]\n",
    "\n",
    "    edge_dict = {}\n",
    "    for cell in cells:\n",
    "        # Create fully connected mesh, including diagonals\n",
    "        for i in range(0, 4):\n",
    "            for j in range(0, 4):\n",
    "                if i == j: \n",
    "                    continue\n",
    "                label, data = make_edge(cell[i], cell[j])\n",
    "                if label not in edge_dict:\n",
    "                    edge_dict[label] = data # Push the edge\n",
    "\n",
    "    # Store de-duplicated bidirectional edges in numpy format\n",
    "    edge_index = np.zeros((2,len(edge_dict)), dtype=np.intc)\n",
    "    edge_features = np.zeros((len(edge_dict),2), dtype=np.float32)\n",
    "\n",
    "    for i, edge in zip(range(0, len(edge_dict)), edge_dict.values()):\n",
    "        edge_index[:,i] = edge\n",
    "        edge_features[i,0] = np.sqrt(np.sum([sim.position[edge[0]]**2, sim.position[edge[1]]**2]))\n",
    "        # print(angle_off_x_axis(delta_vector(sim.position[edge[0]], sim.position[edge[1]])))\n",
    "        edge_features[i,1] = angle_off_x_axis(delta_vector(sim.position[edge[0]], sim.position[edge[1]]))\n",
    "    \n",
    "    return edge_index, edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preparation \n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import InMemoryDataset, Dataset\n",
    "import os\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "class AirFransGeo():\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.data = []\n",
    "        for i in tqdm(indices):\n",
    "            sim = Simulation(DIRECTORY_NAME, self.dataset.extra_data['simulation_names'][i,0])\n",
    "            # sim = extract_dataset_by_simulation('sim', self.dataset, i)\n",
    "            # global_x = sim.input_velocity # These are global inputs for each node in the mesh\n",
    "            inlet_speed = np.linalg.norm(sim.input_velocity, axis=1)\n",
    "            inlet_theta = angle_off_x_axis(sim.input_velocity)\n",
    "\n",
    "            # Negate the angles if y < 0\n",
    "            inlet_theta[np.where(sim.input_velocity[:,1] < 0)] *= -1.0\n",
    "\n",
    "            # X position\n",
    "            position = (sim.position - MEANS['position']) / STDS['position']\n",
    "\n",
    "            # global_x = (global_x - MEANS['speed']) / STDS['speed']\n",
    "            inlet_speed = (inlet_speed - MEANS['speed']) / STDS['speed']\n",
    "\n",
    "            # Find closest airfoil points\n",
    "            surface = np.hstack([sim.position[sim.surface], sim.normals[sim.surface]])\n",
    "            dists = cdist(sim.position, surface[:,:2], metric='euclidean')\n",
    "            best_idx = np.argmin(dists,axis=1).T.tolist()\n",
    "            closest_surfaces = np.take(surface, best_idx, axis=0)\n",
    "\n",
    "            # Vector to closest airfoil point\n",
    "            vector_to_surface = delta_vector(sim.position, closest_surfaces[:,:2])\n",
    "            vector_to_surface = (vector_to_surface - MEANS['position']) / STDS['position']\n",
    "\n",
    "            # Angle (relative to x-axis) to closest airfoil point\n",
    "            surface_theta = angle_off_x_axis(delta_vector(sim.position, closest_surfaces[:,:2]))\n",
    "\n",
    "            # Airfoil distance\n",
    "            surface_distance = (sim.sdf - MEANS['position']) / STDS['position']\n",
    "\n",
    "            # Rotate normal vector 90 degrees, take the angle in the positive x direction\n",
    "            # rotated_normal = rotate(closest_surfaces[:,2:], -np.pi/2)\n",
    "            # rotated_normal[np.where(rotated_normal[:,0]<0)] = rotate(rotated_normal[np.where(rotated_normal[:,0]<0)], np.pi)\n",
    "            # assert(np.min(rotated_normal[:,0]) >= 0.0)\n",
    "            # flow_theta = angle_off_x_axis(rotated_normal)\n",
    "            # flow_theta[np.where(rotated_normal[:,1] < 0)] = -1 * np.abs(flow_theta[np.where(rotated_normal[:,1] < 0)])\n",
    "\n",
    "            # Is_airfoil\n",
    "            is_airfoil = sim.surface.astype(np.float32)\n",
    "\n",
    "            # Y Outlet speed\n",
    "            outlet_speed = np.linalg.norm(sim.velocity, axis=1)\n",
    "            outlet_speed = (outlet_speed - MEANS['speed']) / STDS['speed']\n",
    "\n",
    "            # Y Outlet theta\n",
    "            outlet_theta = angle_off_x_axis(sim.velocity)\n",
    "            outlet_theta[np.where(sim.velocity[:,1] < 0)] *= -1.0\n",
    "\n",
    "            # Y Pressure\n",
    "            outlet_pressure = (sim.pressure - MEANS['pressure']) / STDS['pressure']\n",
    "\n",
    "            # Y Turb\n",
    "            outlet_turb = (sim.nu_t - MEANS['turbulent_viscosity']) / STDS['turbulent_viscosity']\n",
    "\n",
    "            # X and Y coordinates of each point as well as normals (when on airfoil)\n",
    "            x = np.hstack([position, np.expand_dims(inlet_speed,1), \n",
    "                        np.expand_dims(inlet_theta,1), np.expand_dims(is_airfoil,1),\n",
    "                         vector_to_surface, np.expand_dims(surface_theta,1), surface_distance]) #np.expand_dims(flow_theta, 1)]) \n",
    "            y = np.hstack([np.expand_dims(outlet_speed,1), np.expand_dims(outlet_theta,1), outlet_pressure, outlet_turb])\n",
    "            edge_index, edge_attr = make_edges(sim)            \n",
    "\n",
    "            instance = Data(x=torch.from_numpy(x.astype(np.float32)), edge_index=torch.from_numpy(edge_index),\n",
    "                    edge_attr=torch.from_numpy(edge_attr.astype(np.float32)), y=torch.from_numpy(y.astype(np.float32)), \n",
    "                    pos=torch.from_numpy(sim.position.astype(np.float32)))\n",
    "            self.data.append(instance)\n",
    "\n",
    "    def len():\n",
    "        return len(indices)\n",
    "\n",
    "    def get(self,index):\n",
    "        return self.data[index]\n",
    "\n",
    "# Make train and CV splits\n",
    "cv_indices = list(np.array(range(1,int(103/5)),dtype=np.intc)*5)\n",
    "train_indices = []\n",
    "for i in range(0,103):\n",
    "    if i not in cv_indices:\n",
    "        train_indices.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.86s/it]\n",
      "100%|██████████| 1/1 [00:12<00:00, 12.22s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "\n",
    "import pickle\n",
    "\n",
    "TRUNCATED = True\n",
    "REFRESH = True\n",
    "\n",
    "if os.path.exists('train.pkl') and not REFRESH:\n",
    "    file = open('train.pkl', 'rb')\n",
    "    train = pickle.load(file)\n",
    "    file.close()\n",
    "    file = open('cv.pkl', 'rb')\n",
    "    cv = pickle.load(file)\n",
    "    file.close()\n",
    "else:\n",
    "\n",
    "    if TRUNCATED:\n",
    "        train = AirFransGeo(benchmark.train_dataset, train_indices[:1])\n",
    "        cv = AirFransGeo(benchmark.train_dataset, cv_indices[:1])\n",
    "    else:\n",
    "        train = AirFransGeo(benchmark.train_dataset, train_indices)\n",
    "        cv = AirFransGeo(benchmark.train_dataset, cv_indices)\n",
    "\n",
    "        # Save files\n",
    "        file = open(os.path.join('train.pkl'), 'wb')\n",
    "        pickle.dump(train, file)\n",
    "        file.close()\n",
    "        file = open(os.path.join('cv.pkl'), 'wb')\n",
    "        pickle.dump(cv, file)\n",
    "        file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "FEATS = 9\n",
    "NODES = 16\n",
    "OUTPUTS = 4\n",
    "\n",
    "CONV_LAYERS = 8\n",
    "\n",
    "activation = 'GELU'\n",
    "\n",
    "train_loader = DataLoader(train.data, shuffle=False, batch_size=BATCH_SIZE)\n",
    "cv_loader = DataLoader(cv.data, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[170180, 9], edge_index=[2, 1354312], edge_attr=[1354312, 2], y=[170180, 4], pos=[170180, 2], batch=[170180], ptr=[2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for first in train_loader:\n",
    "    break\n",
    "\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to true values\n",
    "x = (first.pos*STDS['position'] + MEANS['position']).numpy()\n",
    "\n",
    "y_true = first.y.numpy().copy()\n",
    "y = y_true.copy()\n",
    "\n",
    "speed = y[:,0]*STDS['speed'] + MEANS['speed']\n",
    "\n",
    "pred_y_vel = np.zeros_like(y[:,1])\n",
    "true_y_vel = np.zeros_like(y[:,1])\n",
    "\n",
    "pred_x_vel = (np.cos(2*np.pi + y[:,1]))*speed\n",
    "pred_y_vel[np.where(y[:,1]<=0)] = np.multiply((np.sin(2*np.pi + np.squeeze(y[np.where(y[:,1]<=0),1]))),speed[np.where(y[:,1]<=0)])\n",
    "pred_y_vel[np.where(y[:,1]>0)] = np.multiply((np.sin(2*np.pi + np.squeeze(y[np.where(y[:,1]>0),1]))),speed[np.where(y[:,1]>0)])\n",
    "\n",
    "true_x_vel = (np.cos(2*np.pi + y_true[:,1]))*speed\n",
    "true_y_vel[np.where(y_true[:,1]<=0)] = np.multiply((np.sin(2*np.pi + np.squeeze(y_true[np.where(y_true[:,1]<=0),1]))),speed[np.where(y_true[:,1]<=0)])\n",
    "true_y_vel[np.where(y_true[:,1]>0)] = np.multiply((np.sin(2*np.pi + np.squeeze(y_true[np.where(y_true[:,1]>0),1]))),speed[np.where(y_true[:,1]>0)])\n",
    "\n",
    "y[:,0] = pred_x_vel\n",
    "y[:,1] = pred_y_vel\n",
    "y[:,2] = (y[:,2]*STDS['pressure']) + MEANS['pressure']\n",
    "y[:,3] = (y[:,3]*STDS['turbulent_viscosity']) + MEANS['turbulent_viscosity']\n",
    "\n",
    "y_true[:,0] = true_x_vel\n",
    "y_true[:,1] = true_y_vel\n",
    "y_true[:,2] = (y_true[:,2]*STDS['pressure']) + MEANS['pressure']\n",
    "y_true [:,3] = (y_true[:,3]*STDS['turbulent_viscosity']) + MEANS['turbulent_viscosity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m y_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(small_y[:,\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     25\u001b[0m y_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(small_y[:,\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m---> 27\u001b[0m interpolator \u001b[38;5;241m=\u001b[39m \u001b[43mRBFInterpolator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmall_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmall_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcubic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# interpolator = RBFInterpolator(small_x, small_y, smoothing=1.0, kernel='gaussian', epsilon=0.0001)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Query coordinates (100x100 grid of points)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m interx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(x_min[\u001b[38;5;241m0\u001b[39m], x_max[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 136\u001b[0m, in \u001b[0;36mRBFInterpolator.__init__\u001b[0;34m(self, y, d, neighbors, smoothing, kernel, epsilon, degree, device)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe data is not compatible with the requested degree.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neighbors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     shift, scale, coeffs \u001b[38;5;241m=\u001b[39m \u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoothing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpowers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_shift\u001b[39m\u001b[38;5;124m\"\u001b[39m, shift)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, scale)\n",
      "Cell \u001b[0;32mIn[2], line 266\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(y, d, smoothing, kernel, epsilon, powers)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolve\u001b[39m(y, d, smoothing, kernel, epsilon, powers):\n\u001b[1;32m    264\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build then solve the RBF linear system\"\"\"\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     lhs, rhs, shift, scale \u001b[38;5;241m=\u001b[39m \u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoothing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpowers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         coeffs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msolve(lhs, rhs)\n",
      "Cell \u001b[0;32mIn[2], line 234\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(y, d, smoothing, kernel, epsilon, powers)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(y, d, smoothing, kernel, epsilon, powers):\n\u001b[1;32m    232\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build the RBF linear system\"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    235\u001b[0m     s \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    236\u001b[0m     r \u001b[38;5;241m=\u001b[39m powers\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[2], line 234\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(y, d, smoothing, kernel, epsilon, powers)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(y, d, smoothing, kernel, epsilon, powers):\n\u001b[1;32m    232\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build the RBF linear system\"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    235\u001b[0m     s \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    236\u001b[0m     r \u001b[38;5;241m=\u001b[39m powers\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:635\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1112\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1090\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:495\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/CFD/venv_cfd/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2197\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2194\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2196\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2197\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2199\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2202\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CFD/venv_cfd/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2266\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2263\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2264\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2266\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2267\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2269\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "center = x[45415, :2]\n",
    "# delta = 0.0069\n",
    "# delta = 0.0069\n",
    "delta = 0.0069\n",
    "\n",
    "# indices = np.where(np.logical_and(np.logical_and(np.greater_equal(x[:,0], center[0]-delta), np.less_equal(x[:,0], center[0]+delta)), \n",
    "#             np.logical_and(np.greater_equal(x[:,1], center[1]-delta), np.less_equal(x[:,1], center[1]+delta))))\n",
    "\n",
    "# index_list = [45394, 45415, 45432, 45438, 45458, 45484, 45331, 45358, 45390]\n",
    "\n",
    "indices = [[45415, 45224, 45225, 45414, 45226, 45416, 45605, 45604, 45606]]\n",
    "\n",
    "# Code to get indices\n",
    "# torch.gather(first.edge_index, 1, torch.unsqueeze(torch.where(first.edge_index[0,:]==45415)[0], 0).repeat(2,1)).numpy()\n",
    "\n",
    "\n",
    "small_x = x[indices[0],:2]\n",
    "small_y = y_true[indices[0],:]\n",
    "\n",
    "x_min = np.min(small_x, axis=0)\n",
    "x_max = np.max(small_x, axis=0)\n",
    "y_min = np.min(small_y[:,2])\n",
    "y_max = np.max(small_y[:,2])\n",
    "\n",
    "interpolator = RBFInterpolator(small_x, small_y, smoothing=1.0, kernel='cubic')\n",
    "# interpolator = RBFInterpolator(small_x, small_y, smoothing=1.0, kernel='gaussian', epsilon=0.0001)\n",
    "\n",
    "# Query coordinates (100x100 grid of points)\n",
    "interx = torch.linspace(x_min[0], x_max[0], 100)\n",
    "intery = torch.linspace(x_min[1], x_max[1], 100)\n",
    "grid_points = torch.meshgrid(interx, intery, indexing='ij')\n",
    "grid_points = torch.stack(grid_points, dim=-1).reshape(-1, 2)\n",
    "\n",
    "# Query RBF on grid points\n",
    "interp_vals = interpolator(grid_points)\n",
    "\n",
    "# Plot the interpolated values in 2D\n",
    "plt.scatter(grid_points[:, 0], grid_points[:, 1], c=interp_vals[:,2], vmin=y_min, vmax=y_max)\n",
    "plt.scatter(*small_x.T, c=small_y[:,2], s=50, ec='k', vmin=y_min, vmax=y_max)\n",
    "plt.title('Interpolated values in 2D')\n",
    "plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.pcolormesh(*grid_points.T, interp_vals[:, 2], vmin=-0.25, vmax=0.25, shading='gouraud')\n",
    "# p = ax.scatter(*small_x.T, c=small_y[:,2], s=50, ec='k', vmin=-0.25, vmax=0.25)\n",
    "# fig.colorbar(p)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 298.15\n",
    "\n",
    "MOL = np.array(28.965338e-3) # Air molar weigth in kg/mol\n",
    "P_ref = np.array(1.01325e5) # Pressure reference in Pa\n",
    "RHO = P_ref*MOL/(8.3144621*T) # Specific mass of air at temperature T\n",
    "NU = -3.400747e-6 + 3.452139e-8*T + 1.00881778e-10*T**2 - 1.363528e-14*T**3 # Approximation of the kinematic viscosity of air at temperature T\n",
    "C = 20.05*np.sqrt(T) # Approximation of the sound velocity of air at temperature T   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # new_x = interx[50]\n",
    "# # new_y = interx[50]\n",
    "# new_x = torch.from_numpy(np.array(x[45415, 0]).copy())\n",
    "# new_y = torch.from_numpy(np.array(x[45415, 1]).copy())\n",
    "# new_x.requires_grad = True\n",
    "# new_y.requires_grad = True\n",
    "\n",
    "# new_interp = interpolator(torch.unsqueeze(torch.stack([new_x, new_y]), 0))\n",
    "# # print(new_interp)\n",
    "# # new_interp[:,2].backward(retain_graph=True)\n",
    "# # # new_x.grad\n",
    "# # new_interp[:,3].backward(retain_graph=True)\n",
    "# # new_interp[:,2].backward(retain_graph=True)\n",
    "# # new_x.zero_grad()\n",
    "# # new_interp[:,2].backward(retain_graph=True)\n",
    "\n",
    "# def val(t):\n",
    "#     return t.detach().numpy().item()\n",
    "\n",
    "# for var, index in zip(['vx', 'vy', 'p', 'nu'], range(4)):\n",
    "#     exec('d_' + var + '= torch.autograd.grad(new_interp[:,' + str(index) + '], [new_x, new_y], retain_graph=True, create_graph=True)')\n",
    "#     exec('d_' + var + '_dx = val(d_' + var + '[0])')\n",
    "#     exec('d_' + var + '_dy = val(d_' + var + '[1])')\n",
    "\n",
    "#     exec('d2_' + var + ' = torch.autograd.grad(d_' + var +'[0], [new_x, new_y], retain_graph=True, create_graph=True)')\n",
    "#     exec('d2_' + var + '_d2x = val(d2_' + var + '[0])')\n",
    "#     exec('d2_' + var + '_dxdy = val(d2_' + var + '[1])')\n",
    "\n",
    "#     exec('d2_' + var + ' = torch.autograd.grad(d_' + var +'[1], [new_x, new_y], retain_graph=True, create_graph=True)')\n",
    "#     exec('d2_' + var + '_d2y = val(d2_' + var + '[1])')\n",
    "\n",
    "# # print(d_vx_dx)\n",
    "# # print(d_vx_dy)\n",
    "# # print(d_vy_dx)\n",
    "# # print(d_vy_dy)\n",
    "\n",
    "# div = d_vx_dx + d_vy_dy\n",
    "# print(div)\n",
    "# # print(div)  #### ROCK ON!!!!\n",
    "\n",
    "# lhs = new_interp[:, 0]*d_vx_dx + new_interp[:, 1]*d_vx_dy\n",
    "# rhs = -d_p_dx + (NU + new_interp[:, 3])*(d2_vx_d2x + d2_vx_d2y)\n",
    "# print(lhs)\n",
    "# print(rhs) \n",
    "# # print(new_interp[:, 3])\n",
    "\n",
    "# # ROCK ON ROCK ON ROCK ON!!!!\n",
    "\n",
    "# print(abs(lhs-rhs))\n",
    "\n",
    "# lhs = new_interp[:, 0]*d_vy_dx + new_interp[:, 1]*d_vy_dy\n",
    "# rhs = -d_p_dy + (NU + new_interp[:, 3])*(d2_vy_d2x + d2_vy_d2y)\n",
    "# print(lhs)\n",
    "# print(rhs) \n",
    "# # print(new_interp[:, 3])\n",
    "\n",
    "# # ROCK ON ROCK ON ROCK ON!!!\n",
    "\n",
    "# print(abs(lhs-rhs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_323899/3834077787.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fdf = first_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 0)\n",
      "/tmp/ipykernel_323899/3834077787.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fdf = first_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 1)\n",
      "/tmp/ipykernel_323899/3834077787.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fdf = first_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 0)\n",
      "/tmp/ipykernel_323899/3834077787.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fdf = first_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 1)\n",
      "/tmp/ipykernel_323899/3834077787.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fdf = first_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 0)\n",
      "/tmp/ipykernel_323899/3834077787.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fdf = first_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 1)\n",
      "/tmp/ipykernel_323899/3834077787.py:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sdf = torch.squeeze(second_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 0))\n",
      "/tmp/ipykernel_323899/3834077787.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sdf = torch.squeeze(second_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 1))\n",
      "/tmp/ipykernel_323899/3834077787.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sdf = torch.squeeze(second_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 0))\n",
      "/tmp/ipykernel_323899/3834077787.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sdf = torch.squeeze(second_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 1))\n",
      "/tmp/ipykernel_323899/3834077787.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sdf = torch.squeeze(second_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 0))\n",
      "/tmp/ipykernel_323899/3834077787.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sdf = torch.squeeze(second_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 1))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'NU' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 195\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mval\u001b[39m(d):\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 195\u001b[0m mass_err, mom_x_err, mom_y_err, new_mass_err, new_mom_x_err, new_mom_y_err \u001b[38;5;241m=\u001b[39m \u001b[43mphys_error\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# new_mass_err\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# length = 170180\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# np.savetxt('data.csv', data, delimiter=',')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 168\u001b[0m, in \u001b[0;36mphys_error\u001b[0;34m(index, x, edge_index, y, device)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Momentum error term (x component)\u001b[39;00m\n\u001b[1;32m    167\u001b[0m lhs \u001b[38;5;241m=\u001b[39m new_interp[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39md_vx_dx \u001b[38;5;241m+\u001b[39m new_interp[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39md_vx_dy\n\u001b[0;32m--> 168\u001b[0m rhs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39md_p_dx \u001b[38;5;241m+\u001b[39m (\u001b[43mNU\u001b[49m \u001b[38;5;241m+\u001b[39m new_interp[:, \u001b[38;5;241m3\u001b[39m])\u001b[38;5;241m*\u001b[39m(d2_vx_d2x \u001b[38;5;241m+\u001b[39m d2_vx_d2y)\n\u001b[1;32m    169\u001b[0m mom_x_err \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(lhs\u001b[38;5;241m-\u001b[39mrhs)\n\u001b[1;32m    170\u001b[0m lhs \u001b[38;5;241m=\u001b[39m new_interp[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mnew_dvx_dx \u001b[38;5;241m+\u001b[39m new_interp[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mnew_dvx_dy\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NU' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def phys_error(index, x, edge_index, y, device):\n",
    "\n",
    "    # Find all neighbors\n",
    "    indices = torch.gather(edge_index, 1, torch.unsqueeze(torch.where(edge_index[0,:]==index)[0], 0).repeat(2,1)).numpy()[1]\n",
    "\n",
    "    # If we have no neighbors, this is probably an airfoil node\n",
    "    if indices.shape[0] == 0:\n",
    "        return torch.tensor(0.0, device=device), torch.tensor(0.0, device=device), torch.tensor(0.0, device=device)\n",
    "\n",
    "    # Not needed - because r**3 == 0\n",
    "    # indices = np.concatenate((np.array([index]), indices[1])) # Add the main index back in\n",
    "\n",
    "    # Cubic interpolation over neighbors\n",
    "    small_x = torch.tensor(x[indices,:2]).to(device)\n",
    "    small_y = torch.tensor(y[indices,:]).to(device)\n",
    "    interpolator = RBFInterpolator(small_x, small_y, smoothing=1.0, kernel='multiquadric', epsilon=1.0, degree=0, device=device)\n",
    "\n",
    "    # Do I need this?\n",
    "    new_x = torch.from_numpy(np.array(x[index, 0]).copy()).to(device)\n",
    "    new_y = torch.from_numpy(np.array(x[index, 1]).copy()).to(device)\n",
    "    new_x.requires_grad = True\n",
    "    new_y.requires_grad = True\n",
    "\n",
    "    n_x = torch.from_numpy(np.array(x[index]).copy()).to(device)\n",
    "    n_x.requires_grad = True\n",
    "    n_y = small_x[:,:2].detach().clone().to(device)\n",
    "    n_y.requires_grad = True\n",
    "\n",
    "    # Calculate interpolated values at the key point\n",
    "    new_interp = interpolator(torch.unsqueeze(torch.stack([new_x, new_y]), 0))\n",
    "\n",
    "    # def first_deriv_func(r, x, y, var):\n",
    "    #     if x.ndim != 2:\n",
    "    #         x = torch.unsqueeze(x, 0)\n",
    "    #     if y.ndim != 2:\n",
    "    #         y = torch.unsqueeze(y, 0)\n",
    "    #     delt = torch.subtract(x[:, var], y[:, var])\n",
    "    #     retval = 3*torch.mul(delt, r)\n",
    "    #     return retval\n",
    "    \n",
    "    # def second_deriv_func(r, x, y, var):\n",
    "    #     if x.ndim != 2:\n",
    "    #         x = torch.unsqueeze(x, 0)\n",
    "    #     if y.ndim != 2:\n",
    "    #         y = torch.unsqueeze(y, 0)\n",
    "    #     delt = torch.subtract(x[:, var], y[:, var])\n",
    "    #     # retval = 3*torch.mul(delt, torch.squeeze((1+r**2)/r))\n",
    "    #     retval = 3*torch.add(delt**2, r**2)/r\n",
    "    #     return retval\n",
    "\n",
    "\n",
    "    def first_deriv_func(r, x, y, var):\n",
    "        if x.ndim != 2:\n",
    "            x = torch.unsqueeze(x, 0)\n",
    "        if y.ndim != 2:\n",
    "            y = torch.unsqueeze(y, 0)\n",
    "        delt = torch.subtract(x[:, var], y[:, var])\n",
    "        retval = -delt / (torch.sqrt(r**2 + 1))\n",
    "        return retval\n",
    "    \n",
    "    def second_deriv_func(r, x, y, var):\n",
    "        if x.ndim != 2:\n",
    "            x = torch.unsqueeze(x, 0)\n",
    "        if y.ndim != 2:\n",
    "            y = torch.unsqueeze(y, 0)\n",
    "        delt = torch.subtract(x[:, var], y[:, var])\n",
    "        # retval = 3*torch.mul(delt, torch.squeeze((1+r**2)/r))\n",
    "        retval = delt**2 / (r**2+1)**(1.5) - 1/(r**2+1)**(0.5) \n",
    "        return retval\n",
    "\n",
    "\n",
    "        # d2terms[k, :neighbors, :] = delts**2 / (torch.unsqueeze((r**2+1)**(1.5) - 1/(r**2+1)**(0.5), 1))\n",
    "    \n",
    "    def first_deriv_poly(scale):\n",
    "        return 1/scale\n",
    "    \n",
    "\n",
    "    # VX\n",
    "    vx_coeffs = interpolator._coeffs[:,0]\n",
    "    y = interpolator.y\n",
    "    fdf = first_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 0)\n",
    "    # fdp = torch.tensor([0.0, first_deriv_poly(interpolator._scale[0]), 0.0], device=device)\n",
    "    fdp = torch.tensor([0.0], device=device)\n",
    "    inputs = torch.cat([torch.squeeze(fdf), fdp])\n",
    "    new_dvx_dx = torch.matmul(inputs, vx_coeffs)\n",
    "\n",
    "    # Still looking @ VX!\n",
    "    fdf = first_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 1)\n",
    "    # fdp = torch.tensor([0.0, 0.0, first_deriv_poly(interpolator._scale[1])], device=device)\n",
    "    inputs = torch.cat([torch.squeeze(fdf), fdp])\n",
    "    new_dvx_dy = torch.matmul(inputs, vx_coeffs)\n",
    "\n",
    "    # VY\n",
    "    vy_coeffs = interpolator._coeffs[:,1]\n",
    "    fdf = first_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 0)\n",
    "    # fdp = torch.tensor([0.0, first_deriv_poly(interpolator._scale[0]), 0.0], device=device)\n",
    "    inputs = torch.cat([torch.squeeze(fdf), fdp])\n",
    "    new_dvy_dx = torch.matmul(inputs, vy_coeffs)\n",
    "\n",
    "    fdf = first_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 1)\n",
    "    # fdp = torch.tensor([0.0, 0.0, first_deriv_poly(interpolator._scale[1])], device=device)\n",
    "    inputs = torch.cat([torch.squeeze(fdf), fdp])\n",
    "    new_dvy_dy = torch.matmul(inputs, vy_coeffs)\n",
    "\n",
    "    # P\n",
    "    p_coeffs = interpolator._coeffs[:,2]\n",
    "    fdf = first_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 0)\n",
    "    # fdp = torch.tensor([0.0, first_deriv_poly(interpolator._scale[0]), 0.0], device=device)\n",
    "    inputs = torch.cat([torch.squeeze(fdf), fdp])\n",
    "    new_dp_dx = torch.matmul(inputs, p_coeffs)\n",
    "\n",
    "    fdf = first_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 1)\n",
    "    # fdp = torch.tensor([0.0, 0.0, first_deriv_poly(interpolator._scale[1])], device=device)\n",
    "    inputs = torch.cat([torch.squeeze(fdf), fdp])\n",
    "    new_dp_dy = torch.matmul(inputs, p_coeffs)\n",
    "\n",
    "    # Now 2nd derivatives\n",
    "    sdf = torch.squeeze(second_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 0))\n",
    "    new_d2vx_d2x = torch.matmul(sdf, vx_coeffs[:sdf.shape[0]])\n",
    "    sdf = torch.squeeze(second_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 1))\n",
    "    new_d2vx_d2y = torch.matmul(sdf, vx_coeffs[:sdf.shape[0]])\n",
    "\n",
    "    sdf = torch.squeeze(second_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 0))\n",
    "    new_d2vy_d2x = torch.matmul(sdf, vy_coeffs[:sdf.shape[0]])\n",
    "    sdf = torch.squeeze(second_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 1))\n",
    "    new_d2vy_d2y = torch.matmul(sdf, vy_coeffs[:sdf.shape[0]])\n",
    "\n",
    "    sdf = torch.squeeze(second_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 0))\n",
    "    new_d2p_d2x = torch.matmul(sdf, p_coeffs[:sdf.shape[0]])\n",
    "    sdf = torch.squeeze(second_deriv_func(torch.cdist(torch.unsqueeze(n_x,0), y), torch.tensor(n_x, device=device), y, 1))\n",
    "    new_d2p_d2y = torch.matmul(sdf, p_coeffs[:sdf.shape[0]])\n",
    "\n",
    "    # Calculate needed derivatives\n",
    "\n",
    "    # VX\n",
    "    d_vx = torch.autograd.grad(new_interp[:,0], [new_x, new_y], retain_graph=True, create_graph=True)\n",
    "    d_vx_dx = d_vx[0]\n",
    "\n",
    "    d_vx_dy = d_vx[1]\n",
    "\n",
    "    d2_vx = torch.autograd.grad(d_vx[0], [new_x, new_y], retain_graph=True, create_graph=True)\n",
    "    d2_vx_d2x = d2_vx[0]\n",
    "\n",
    "    d2_vx = torch.autograd.grad(d_vx[1], [new_x, new_y], retain_graph=True, create_graph=True)\n",
    "    d2_vx_d2y = d2_vx[1]\n",
    "\n",
    "    # VY\n",
    "    d_vy = torch.autograd.grad(new_interp[:,1], [new_x, new_y], retain_graph=True, create_graph=True)\n",
    "    d_vy_dx = d_vy[0]\n",
    "    d_vy_dy = d_vy[1]\n",
    "\n",
    "    d2_vy = torch.autograd.grad(d_vy[0], [new_x, new_y], retain_graph=True, create_graph=True)\n",
    "    d2_vy_d2x = d2_vy[0]\n",
    "\n",
    "    d2_vy = torch.autograd.grad(d_vy[1], [new_x, new_y], retain_graph=True, create_graph=True)\n",
    "    d2_vy_d2y = d2_vy[1]\n",
    "\n",
    "    # P\n",
    "    d_p = torch.autograd.grad(new_interp[:,2], [new_x, new_y], retain_graph=True, create_graph=True)\n",
    "    d_p_dx = d_p[0]\n",
    "    d_p_dy = d_p[1]\n",
    "\n",
    "    # Conservation of mass error term (should be 0)\n",
    "    mass_err = torch.abs(torch.add(d_vx_dx, d_vy_dy))\n",
    "    new_mass_err = torch.abs(torch.add(new_dvx_dx, new_dvy_dy))\n",
    "\n",
    "    # Momentum error term (x component)\n",
    "    lhs = new_interp[:, 0]*d_vx_dx + new_interp[:, 1]*d_vx_dy\n",
    "    rhs = -d_p_dx + (NU + new_interp[:, 3])*(d2_vx_d2x + d2_vx_d2y)\n",
    "    mom_x_err = torch.abs(lhs-rhs)\n",
    "    lhs = new_interp[:, 0]*new_dvx_dx + new_interp[:, 1]*new_dvx_dy\n",
    "    rhs = -new_dp_dx + (NU + new_interp[:, 3])*(new_d2vx_d2x + new_d2vx_d2y)\n",
    "    new_mom_x_err = torch.abs(lhs-rhs)\n",
    "\n",
    "\n",
    "    # Momentum error term (y component)\n",
    "    lhs = new_interp[:, 0]*d_vy_dx + new_interp[:, 1]*d_vy_dy\n",
    "    rhs = -d_p_dy + (NU + new_interp[:, 3])*(d2_vy_d2x + d2_vy_d2y)\n",
    "    mom_y_err = torch.abs(lhs-rhs)\n",
    "    lhs = new_interp[:, 0]*new_dvy_dx + new_interp[:, 1]*new_dvy_dy\n",
    "    rhs = -new_dp_dy + (NU + new_interp[:, 3])*(new_d2vy_d2x + new_d2vy_d2y)\n",
    "    new_mom_y_err = torch.abs(lhs-rhs)\n",
    "\n",
    "    return mass_err, mom_x_err, mom_y_err, new_mass_err, new_mom_x_err, new_mom_y_err\n",
    "\n",
    "surface = torch.where(first.x[:,4]!=0.0)[0]\n",
    "\n",
    "# Remove surface edges first\n",
    "edge_mask = ~torch.isin(first.edge_index[:,:], surface)\n",
    "non_surface = torch.any(edge_mask, dim=0)\n",
    "edge_index = first.edge_index[:,non_surface]\n",
    "\n",
    "def val(d):\n",
    "    return d.detach().cpu().numpy().item()\n",
    "\n",
    "mass_err, mom_x_err, mom_y_err, new_mass_err, new_mom_x_err, new_mom_y_err = phys_error(5, x, edge_index, y_true, 'cuda')\n",
    "\n",
    "# new_mass_err\n",
    "\n",
    "# length = 170180\n",
    "# data = np.zeros((length, 6), dtype=np.float32)\n",
    "# for i in tqdm(range(length)): #tqdm(range(x.shape[0])):\n",
    "#     mass_err, mom_x_err, mom_y_err, new_mass_err, new_mom_x_err, new_mom_y_err = phys_error(i, x, edge_index, y_true, 'cuda')\n",
    "#     data[i, 0] = val(mass_err)\n",
    "#     data[i, 1] = val(mom_x_err)\n",
    "#     data[i, 2] = val(mom_y_err)\n",
    "#     data[i, 3] = val(new_mass_err)\n",
    "#     data[i, 4] = val(new_mom_x_err)\n",
    "#     data[i, 5] = val(new_mom_y_err)\n",
    "\n",
    "# np.savetxt('data.csv', data, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cfd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
